<html>
<HEAD>
<title>Scanning and Parsing</title>
</HEAD>
<BODY>
<h1><A NAME="xtocid135565">Scanning and Parsing</A></h1>

Up to now we have had to deal with competing "board" and "SML
datatype" notations for the same <strong>D</strong> programs.  We want
to get around this problem by writing a <em>parser</em> for
<strong>DSR</strong>, a function from the board-representation strings
to <code>term</code> datatype members.

<p>
<strong>Goal:</strong> given <strong>DSR</strong> program as string
(in the board representation),
produce <strong>DSR</strong> <code>term</code> datatype member.<p>

We are going to use a simple <a href="../sml/class/arith-parser.sml">parser for an arithmetic language</a> as an
example to convey the basic concepts.
<h2><A NAME="xtocid135566">Pre-processing the string: scannning</A></h2>
Parsing always includes a pre-processing phase, <em>scanning</em> or
<em>lexical analysis</em>.  <br>
Group the string into quantum chunks,
<em>tokens</em>.<br>
Why?  Makes parsing easier and faster.
<pre>
structure Lex = struct
  datatype ide = IDE of string
  datatype token
    = INT of int
    | BOOL of bool
    | VARIDE of ide
    | LPAREN | RPAREN
    | PLUS | TIMES
    | EOF
end
</pre>
<strong>Definition:</strong> a scanner (lexical analyzer) is a
function <code>lex : string -> Lex.token list</code> where
<code>Lex.token</code> is a datatype of atomic symbols of the
language.
<p>

Terminology: strings representing atoms are <em>lexemes</em> ("+",
"=>, "THEN", ...); each lexeme has a compact <em>token</em>
representation as a member of the <code>token</code> datatype.<br>
A few tokens are a bit hairy because they are parametric and have many
possible lexemes ("<code>3434</code>", "<code>aVariable</code>").

<pre>
lex "(2 + x * 5 + 4)";
<em>val it = [LPAREN,INT 2,PLUS,VARIDE (IDE "x"),TIMES,INT 5,PLUS,INT 4,RPAREN]
  : token list
-</em> </pre>

The parser then uses the scanner as a subroutine to return a token whenever
it needs one.  
<pre>
- parseString("(2 + x * 5 + 4)"));
val it = PLUS (PLUS (INT 2,TIMES (VAR (IDE "x"),INT 5)),INT 4)
  : term
</pre>

<h3><A NAME="xtocid135567">Writing a Scanner</A></h3>

This is not an overly difficult programming problem.  Example code
assumes the characters will be read off of a stream (which can be
either a file or a string) and a stream of tokens produced.

<pre>type 'a stream = {
  next : unit -> unit, (* get next element *)
  peek : unit -> 'a,   (* peek at first character on stream *)
  close : unit -> unit 
}
</pre>
Main function is to get the next token from the stream,
<code>getToken()</code>.  <br>
Iterating this produces a stream (or list) of tokens.
<br>
Here is a sketch of <code>getToken</code>:
<pre>
fun getToken () =
  let currChar = peek() in
         next ();
	 case currChar of #"\000" => EOF
	  | (#" " | #"\n" | #"\t") => getToken () (* junk; continue *)
	  | #"(" => LPAREN
	  | #")" => RPAREN
	  | #"+" => PLUS
	  | #"*" => TIMES
	  | ch =>
	    if isDigit ch then INT (getNum (ord ch - ord #"0")) (* build number *)
	    else if isAlphaNum ch then
	      case getAlpha ch   (* get next word from stream *)
	       of "TRUE" => BOOL true
		| "FALSE" => BOOL false
		| s => VARIDE (IDE s)
	    else raise Error
  end
</pre>
<h3><A NAME="xtocid1022868">Lex</A></h3>
<code>lex</code> is a tool for automatically building a scanner from a
list of regular expressions for the lexemes.  It produces C code
output.  There is also a verion of lex for SML, <code>ML-lex</code>.

<h2><A NAME="xtocid135568">Grammars</A></h2>
Underlying the theory of parsing is the concept of a <em>grammar</em>.<p>

Grammars
<ol>
  <li> Define a nondeterminitic machine which, with no input, produces
       a string as output; 
  <li> define a language of strings (L(G)), the set of strings a
       particular grammar can produce;
  <li> Not only produces strings as output, but produces a grammar
       derivation for that string, which is a tree.
</ol>
This is very useful for parsing programs, because
<ol>
  <li> The token strings representing legal programs may be defined as
       being generated by a grammar; and,
  <li> Given such a grammar, the grammar derivation trees are "very
       close" to the trees corresponding to <code>term</code> datatype
       members such as <code>PLUS (PLUS (INT 2,TIMES (VAR (IDE "x"),INT 5)),INT 4)</code>.
</ol>
A Grammar G is a set of rules mapping <em>nonterminals</em> to strings of
terminals and nonterminals.

D's <code>term</code> datatype is very close to the following D grammar:
<pre>
term -> FN ide => term | term term | term + term | term = term |
         IF term THEN term ELSE term | var | int | ( term )
var -> ide
ide -> (any string)
int -> (any number)
</pre>
An example rule is <code>term -> FN ide => term</code>, with terminals
<code>FN =></code> and nonterminals <code>ide term</code>.<p>

The <code>|</code> notation allows many cases, much as in SML.<p>

The datatype defines <em>abstract</em> syntax trees,
<pre>
              PLUS
              /  \
            INT TIMES
            /   /   \
           2  VAR  INT
               |    |
              IDE   5
               |
              "x"
</pre>
while the above
grammar produces <em>concrete</em> syntax trees that include
<code>=></code> and other irrelevant syntax.
<pre>
                 term
                /  |  \
               (  term )
                 / | \
              term + term
               |    /  | \
              int var  * int
               |   |      |
               2  ide     5
                   |
                  "x"

</pre>
<ul>
  <li> An infix walk through this tree yields the precise token string.
  <li> Construction of abstract tree from concrete tree is a simple
       task (in practice, we don't actually ever construct the
       concrete tree).
</ul>

<h4><A NAME="xtocid1022870">Other forms of syntax presentation</A></h4>
Backus-Naur Form (BNF): a common way of presenting syntax for a
programming language; it is a 
grammar which uses <code>::=</code> in place of <code>-></code>.<p>

Syntax diagrams (use of arrows and loops) are another equivalent form,
and are used in Ullman (see e.g. p. 260 of Ullman).<p>

The D grammar above (as well as most language grammar specs, including
the one in Ullman) is however <em>ambiguous</em>: different grammar 
derivations of same string possible, meaning different concrete syntax
trees possible. <p>

Ambiguous grammars are no good for parsing: 
<ul>
  <li> given a program string,
more than one tree may be produced, meaning it is unclear what
datatype member the program is.
  <li> Most parsing methods are fairly automatic once an unambiguous
       grammar has been given.
</ul>
<p>

Conclusion: re-write grammar to an equivalent but unambiguous
grammar.  
<p>

<h3><A NAME="xtocid135569">Making Grammars Unambiguous</A></h3>
This is an art; we proceed by example which solves the common problem of
multiple infix operators of different precedence having left associativity.
<p>

Example grammar: simple arithmetic over identifiers.
<pre>E -> E + E | E * E | id | (E)
</pre>
(note, this denotes a language with five tokens, <code>+ * id ( )</code>)<br>

This grammar is ambiguous, in two ways:

1: <code>id*id+id</code> precedence problem:
<pre>
             E
            /|\
           E + E
          /|\
         E * E


             E
            /|\
           E * E
              /|\
             E + E
</pre>
second tree is bad. Need: "<code>*</code> has precedence over <code>+</code>"
<p>


2: <code>id+id+id</code> associativity problem (still get the two
trees above, replacing the "<code>*</code>" by "<code>+</code>".
<p>
Besides these two problems, every string produces a unique tree.
<br>
Solving these two problems:
<p>


First: enforce proper operator precedence.  <code>*</code> binds more
tightly than <code>+</code>.
<p>

Idea: no +'s off to the right of a * node: rules out second tree above. <br>

Solution: new symbol T for *'s that has no +'s allowed.

<pre>E -> E + E | T
T -> T * T | id | (E)
</pre>
now, * nodes can't have + nodes below.  In general, with n operators
of varying precedence this technique can be used.
<br>
note, need to use E -> T if there are no +'s at top
<p>


Next: want to rule out subtree

<pre>             E
            /|\
           E + E
              /|\
             E + E

</pre> 

Solution: 

<pre>E -> E + T | T
...
</pre>
Similar for T * T: no * wanted on right:

<pre>T -> T * F | F
F -> id | (E)
</pre>
The final grammar:

<pre>
E -> E + T | T
T -> T * F | F
F -> id | (E)
</pre>
<strong>Assert:</strong> This grammar is unambiguous.

<h3><A NAME="xtocid1022872">Parsing Given an Unambiguous Grammar</A></h3>
There are two schools (algorithms) of parsing.
<ol>
  <li> Top-down parsing, LL(1)
  <li> Bottom-up parsing, LR(1)
</ol>
We are going to present 1. only, for brevity.  The UNIX C tool
<code>yacc</code> (and <code>ML-yacc</code>) automatically generates
an LR(1) parser from a grammar.

<h3><A NAME="xtocid135570">Top-down parsing algorithm</A></h3>

We are going to parse programs by building a grammar derivation tree
(concrete syntax tree) as follows.
<ol>
  <li> starting initially at the top of the tree with the start
       symbol, in this case <code>E</code>;
  <li> scanning the input tokens in left-to-right order;
  <li> building the tree in pre-order traversal order, by applying
       grammar rules one at a time;
  <li> only looking one token ahead to decide how to extend derivation
       tree next. 
</ol>
The trick is deciding which grammar rule to apply at the current point
we are extending the tree from.  
<h3><A NAME="xtocid135571">Making Grammars LL(1)</A></h3>

This grammar is unambiguous but it is not LL(1), meaning from a single
next character it is <em>impossible</em> to decide which rule to apply.
<p>

Problem: given input <code>id+id+id+id</code> -- how many <code>E -> E +
T</code> nodes to string out?  <br>
Answer is 3, but is impossible to tell without looking at almost whole input.<br>
Violates one-character lookahead restriction, necessary to keep
algorithm linear and not quadratic.
<p>

In general, top-down parsing weakness is with left recursion: 
<code>A -> A ...</code>
<p>

<strong>Fact:</strong> no grammar with left recursion is LL(1)<p>

<strong>Solution:</strong> replace <code>E -> E + T | T</code>, which
really generates <code>T + T + ... T</code> (think about it) by rule
<pre>E -> T {+ T }*
</pre>
(<code>{ blah }*</code> means 0 or more <code>blah</code>'s in sequence)
--grammar has same strings but no left recursion.<br>
Similar strategy for left recursion for <code>*</code>.<p>

<h3><A NAME="xtocid135572">Writing a top-down parser</A></h3>
Main idea: one recursive function to parse each nonterminal of the grammar.<br>

Abstract idea:
<ul>
  <li> We are somewhere in the middle of building the parse tree,
       reading tokens off the stream;
  <li> The next (leftmost) nonterminal in the tree for which the parse
       tree has not been built yet is <code>X</code>;
  <li> There is a function <code>parseX</code> to parse grammar rule <code>X</code>.
  <li> We invoke <code>parseX()</code>; it should build the entire
       tree for that node, reading tokens off the stream it uses.
</ul>
Given one such function for every grammar rule, they can call each
other to build the tree.  For instance, suppose a grammar had a rule
<pre>
Q -> [ E ]
</pre>
function <code>parseQ</code> reads off a token which should be a
<code>[</code>, calls <code>parseE</code> to build that
<em>entire</em> tree, and reads off a final token
which should be a <code>]</code>.  Done.<br>

This is known as a <em>recursive descent parser</em>. <p>

The following pseudocode is derived from the actual <a
href="../sml/class/arith-parser.sml">arith parser</a> (which is
programmed in a more general style).

<pre>
(* This function has the responsibility of parsing a nonterminal F of
the grammar, using tokens on the current token stream.  It must
generate the complete parse tree for that particular nonterminal. *)

fun parseF () = case peek ()
   of Lex.ID v => (next (); ID v)  (* skip by the token and build datatype result *)
    | Lex.LPAREN => next (); parseE()
      before (case peek () of Lex.RPAREN => next () | _ => raise Error)
                                                         (* ^ parens unbalanced *)
    | _ => raise Error (* illegal token at this point *)

(* build a complete grammar derivation for the T nonterminal:
   F * F * F * F * ... * F * F * F, or just F
*)

fun parseT () = let
  fun loop term =
    case peek () of
      Lex.TIMES => next();    (* another F in the list ... *)
                   loop (TIMES (term, parseF ()))  (* build datatype *)
      | _ => term    (* no more *'s therefore no more F's in the list; return *)
  in loop (parseF () (* first, parse the first F in the list *)) end


(* build a complete grammar derivation for the E nonterminal:
T * T * T * T * ... * T * T * T, or just T
*)

fun parseE () = let
  fun loop term =
    case peek () of
      Lex.PLUS => next();
                   loop (PLUS (term, parseT ()))
      | _ => term
        in loop (parseT ()) end

 
fun parse () = parseE ()
</pre>


<h3><A NAME="xtocid1022876">Parsing other languages</A></h3>
The above ideas pretty much work for any language grammar where
<ul>
  <li> The language may have any number of operators with a fixed
       precedence order;
  <li> All other grammar rules have a unique first
       terminal symbol on every different rule to allow the choice of
       tree to be made (as with the <code>F</code> grammar rules). 
</ul>
One other grammar that is difficult is one where the <code>else</code>
clause of an <code>if-then-else</code> is optional:

<pre>
C -> IF E THEN C ELSE C | IF E THEN C</pre>
--there are two choices of the tree to build below <code>C</code>, and
the initial terminal, <code>IF</code>, does not help in making the
choice.  <br>
In such cases we can often hack up solutions <br>
(here, after parsing the
first <code>C</code>, if the next token is <code>ELSE</code> we are in
the left case, and otherwise assume the right case).
<br>
In general it may be impossible to surmount the difficulties, however.<br>
LR(1) method is somewhat more flexible, but conceptually more difficult.
</body></html>
